{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7883788e-f770-4307-84f7-7b388b5f907c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhh/CodeServer/RevAnalytix/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m softmax\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m notebook_tqdm\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from .autonotebook import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9186b144-a0bc-45c8-a5ed-2cb21b2e676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and tokenizer\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73fc3f73-de8b-4104-983b-9c225f7695c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3280da5-b290-4e0f-949c-8d42ef6d1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess text\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e3c651-dc2c-42d8-a8dd-c3153d945e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform sentiment analysis\n",
    "def perform_sentiment_analysis(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # Rank the sentiment labels by their scores\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    sentiments = []\n",
    "    \n",
    "    # Print labels and scores\n",
    "    for i in range(scores.shape[0]):\n",
    "        label = config.id2label[ranking[i]]\n",
    "        score = scores[ranking[i]]\n",
    "        sentiments.append((label, np.round(float(score), 4)))\n",
    "    \n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6aa54c-0aa4-4484-b183-969456034fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your review:  The app is wonderful! I love the characters, and everything. But what I don't like is the characters forgetting things to easily. The AI's keep repeating, and it gets annoying!!! There are a lot of bugs, but overall the app is good. I also think they need to make a kids ver, and an adult ver! Also not to mention the amount of times the server goes down and I have to wait for hours!!! I don't have $10 to pay for y'all's Talkie+, it's outrageous!!! There should be better severs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis Results:\n",
      "1) negative: 0.5088\n",
      "2) positive: 0.3315\n",
      "3) neutral: 0.1597\n"
     ]
    }
   ],
   "source": [
    "# Get input from the user\n",
    "user_input = input(\"Enter your review: \")\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sentiments = perform_sentiment_analysis(user_input)\n",
    "\n",
    "# Print the sentiment analysis results\n",
    "print(\"\\nSentiment Analysis Results:\")\n",
    "for i, (label, score) in enumerate(sentiments):\n",
    "    print(f\"{i+1}) {label}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ff710cd-1a84-4db7-8dd9-38982eb260a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform sentiment analysis and capture concerns\n",
    "def perform_sentiment_and_concern_analysis(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # Define positive keywords and concern keywords\n",
    "    positive_keywords = [\"happy\", \"great\", \"excellent\", \"awesome\"]\n",
    "    concern_keywords = [\"issue\", \"problem\", \"concern\", \"trouble\", \"complaint\"]\n",
    "    \n",
    "    # Check for the presence of keywords\n",
    "    detected_sentiment = None\n",
    "    detected_concerns = []\n",
    "    \n",
    "    for keyword in positive_keywords:\n",
    "        if keyword in text:\n",
    "            detected_sentiment = \"Positive\"\n",
    "            break\n",
    "    \n",
    "    for keyword in concern_keywords:\n",
    "        if keyword in text:\n",
    "            detected_concerns.append(keyword)\n",
    "    \n",
    "    if detected_sentiment:\n",
    "        return detected_sentiment, detected_concerns, scores\n",
    "    else:\n",
    "        # If no sentiment keywords found, rank the sentiment labels by their scores\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        sentiments = []\n",
    "        \n",
    "        # Print labels and scores\n",
    "        for i in range(scores.shape[0]):\n",
    "            label = config.id2label[ranking[i]]\n",
    "            score = scores[ranking[i]]\n",
    "            sentiments.append((label, np.round(float(score), 4)))\n",
    "        \n",
    "        return sentiments, detected_concerns, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "977ec061-f0f1-47c9-829d-57b53acfa482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your review:  The app is wonderful! I love the characters, and everything. But what I don't like is the characters forgetting things to easily. The AI's keep repeating, and it gets annoying!!! There are a lot of bugs, but overall the app is good. I also think they need to make a kids ver, and an adult ver! Also not to mention the amount of times the server goes down and I have to wait for hours!!! I don't have $10 to pay for y'all's Talkie+, it's outrageous!!! There should be better severs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis Results:\n",
      "1) negative: 0.5088\n",
      "2) positive: 0.3315\n",
      "3) neutral: 0.1597\n"
     ]
    }
   ],
   "source": [
    "# Get input from the user\n",
    "user_input = input(\"Enter your review: \")\n",
    "\n",
    "# Perform sentiment and concern analysis\n",
    "result, detected_concerns, scores = perform_sentiment_and_concern_analysis(user_input)\n",
    "\n",
    "# Print the sentiment analysis results and detected concerns\n",
    "if isinstance(result, str):\n",
    "    print(\"Sentiment:\", result)\n",
    "else:\n",
    "    print(\"\\nSentiment Analysis Results:\")\n",
    "    for i, (label, score) in enumerate(result):\n",
    "        print(f\"{i+1}) {label}: {score}\")\n",
    "\n",
    "if detected_concerns:\n",
    "    print(\"\\nDetected Concerns:\", \", \".join(detected_concerns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c1cd5-957d-40d3-b36c-0af628888e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
