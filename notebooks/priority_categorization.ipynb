{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae881a3f-40a3-4022-b899-5813b8870bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d44da3-de65-45e8-abe2-ac5c581dc57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Preprocess function\n",
    "def preprocess(text):\n",
    "    # Convert emojis to their text representation\n",
    "    text = emoji.demojize(text)\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv('data/in.evolve.android.csv')\n",
    "\n",
    "# Initialize sentiment analysis model and tokenizer\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Lists to store sentiment and sentiment scores\n",
    "sentiments = []\n",
    "sentiment_scores = []\n",
    "\n",
    "# Chunk size for processing long texts\n",
    "chunk_size = 256\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    text = preprocess(row['content'])\n",
    "    \n",
    "    # Split the text into chunks\n",
    "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    \n",
    "    chunk_scores = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if chunk:\n",
    "            encoded_input = tokenizer(\n",
    "                chunk,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            output = model(**encoded_input)\n",
    "            scores = output[0][0].detach().numpy()\n",
    "            scores = softmax(scores)\n",
    "            ranking = np.argsort(scores)\n",
    "            ranking = ranking[::-1]\n",
    "        \n",
    "            # Get the top sentiment label and score for the chunk\n",
    "            top_label = config.id2label[ranking[0]]\n",
    "            top_score = np.round(float(scores[ranking[0]]), 4)\n",
    "        \n",
    "            chunk_scores.append(top_score)\n",
    "    \n",
    "    # Calculate the average score for all chunks if there are scores\n",
    "    if chunk_scores:\n",
    "        average_score = np.mean(chunk_scores)\n",
    "    else:\n",
    "        average_score = np.nan\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    sentiments.append(top_label)\n",
    "    sentiment_scores.append(average_score)\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df['sentiment'] = sentiments\n",
    "df['sentiment_score'] = sentiment_scores\n",
    "\n",
    "# Define priority levels based on sentiment scores\n",
    "def categorize_priority(score):\n",
    "    if score >= 0.75:\n",
    "        return 'P1'  # most negative reviews\n",
    "    elif score >= 0.50:\n",
    "        return 'P2'  # moderately negative reviews\n",
    "    else:\n",
    "        return 'P3'  # least negative reviews\n",
    "\n",
    "# Apply the function to the 'sentiment_score' column for negative reviews\n",
    "df.loc[df['sentiment'] == 'negative', 'priority'] = df.loc[df['sentiment'] == 'negative', 'sentiment_score'].apply(categorize_priority)\n",
    "\n",
    "# Save the DataFrame with the new columns \n",
    "df.to_csv('data/neg_neu_pos_priority.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d135168-3f2e-49af-9205-200cfb1acaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(text):\n",
    "    # Convert emojis to their text representation\n",
    "    text = emoji.demojize(text)\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv('data/in.evolve.android.csv')\n",
    "\n",
    "# Initialize sentiment analysis model and tokenizer\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Function to perform sentiment analysis and categorize priority\n",
    "def sentiment_analysis_and_priority(row):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess(row['content'])\n",
    "    \n",
    "    # Split the text into chunks\n",
    "    chunk_size = 256\n",
    "    chunks = [preprocessed_text[i:i+chunk_size] for i in range(0, len(preprocessed_text), chunk_size)]\n",
    "    \n",
    "    chunk_scores = []\n",
    "    \n",
    "    # Initialize scores with a default value\n",
    "    scores = np.array([0.0, 0.0, 0.0])\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if chunk:\n",
    "            encoded_input = tokenizer(chunk, return_tensors='pt')\n",
    "            output = model(**encoded_input)\n",
    "            scores = output[0][0].detach().numpy()\n",
    "            scores = softmax(scores)\n",
    "            ranking = np.argsort(scores)\n",
    "            ranking = ranking[::-1]\n",
    "        \n",
    "            # Get the top sentiment label and score for the chunk\n",
    "            top_label = config.id2label[ranking[0]]\n",
    "            top_score = np.round(float(scores[ranking[0]]), 4)\n",
    "        \n",
    "            chunk_scores.append(top_score)\n",
    "    \n",
    "    # Calculate the average score for all chunks if there are scores\n",
    "    if chunk_scores:\n",
    "        average_score = np.mean(chunk_scores)\n",
    "        sentiment_score = average_score\n",
    "    else:\n",
    "        sentiment_score = np.nan\n",
    "    \n",
    "    # The order of labels in this model is ['negative', 'neutral', 'positive']\n",
    "    sentiment = ['negative', 'neutral', 'positive'][np.argmax(scores)]\n",
    "    \n",
    "    # Categorize priority based on sentiment and rating\n",
    "    if sentiment == 'negative':\n",
    "        # Use the probability score of the negative sentiment and the rating to categorize priority\n",
    "        negative_score = scores[0]\n",
    "        rating = row['score']\n",
    "        if negative_score > 0.6 or rating <= 2:\n",
    "            priority = 'P1'\n",
    "        elif negative_score > 0.3 or rating == 3:\n",
    "            priority = 'P2'\n",
    "        else:\n",
    "            priority = 'P3'\n",
    "    else:\n",
    "        priority = None\n",
    "    \n",
    "    return sentiment, sentiment_score, priority\n",
    "\n",
    "# Apply sentiment analysis and priority categorization to the data\n",
    "df[['sentiment', 'sentiment_score', 'priority']] = df.apply(sentiment_analysis_and_priority, axis=1, result_type='expand')\n",
    "\n",
    "# Save the processed data to a new CSV file\n",
    "df.to_csv('data/processed_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43f970-56b1-4653-903d-24ec653bb04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4509a52-433e-4698-a1cb-2d3bbf261b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1b994-fb17-4bca-ac98-fe174db597db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc282663-76e4-42ef-b78a-88ad5ae2c663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
